{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "887a5381",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b34be",
   "metadata": {},
   "source": [
    "# Caso-taller:  Recomendando el Blog de  Hernán Casciari \n",
    "\n",
    "\n",
    "[Hernán Casciari](https://hernancasciari.com/#bio), es un escritor argentino, que escribe blog posts con cuentos e historias  relacionadas con el futbol, su vida, infancia, y relaciones familiares con toques de ficción. Este [blog](https://hernancasciari.com/blog/) es  tan interesantes que en 2005 fue premiado como “El mejor blog del mundo” por Deutsche Welle de Alemania. \n",
    "\n",
    "El objetivo de este caso-taller es construir un sistema de recomendación basado en los contenidos de los posts utilizando similitud de las palabras usadas o temas de los cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063f639d",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "1. Para desarrollar el *cuaderno* primero debe descargarlo.\n",
    "\n",
    "2. Para responder cada inciso deberá utilizar el espacio debidamente especificado.\n",
    "\n",
    "3. La actividad será calificada sólo si sube el *cuaderno* de jupyter notebook con extensión `.ipynb` en la actividad designada como \"Revisión por el compañero.\"\n",
    "\n",
    "4. El archivo entregado debe poder ser ejecutado localmente por los pares. Sea cuidadoso con la especificación de la ubicación de los archivos de soporte, guarde la carpeta de datos  en la misma ruta de acceso del cuaderno, por ejemplo: `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157021ca",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a708b382",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "En la carpeta `data` se encuentran el archivo `blog_casciari.csv` con el título, la fecha de publicación, y el contenido de los cuentos publicados en el blog  de sr. Casciari. Cargue estos datos en su *cuaderno* y reporte brevemente el contenido de la base.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81194374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab1c366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles en el dataset:\n",
      "Index(['titulo', 'fecha', 'cuento'], dtype='object')\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "                       titulo    fecha  \\\n",
      "0            El rincón blanco  1/11/08   \n",
      "1  Mínimos avances en la cama  1/24/08   \n",
      "2                  Don Marcos  2/19/08   \n",
      "3              Los dos rulfos  3/26/08   \n",
      "4   La noticia no es el perro  4/15/08   \n",
      "\n",
      "                                              cuento  \n",
      "0  De pronto yo estaba en el hogar donde pasé la ...  \n",
      "1  Menos la cama, todo ha mejorado en este mundo....  \n",
      "2  Dos veces, y no una, mi abuelo materno me ayud...  \n",
      "3  A su regreso de México, mi amigo Comequechu no...  \n",
      "4  De repente, un video de You Tube recibe un mil...  \n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   titulo  520 non-null    object\n",
      " 1   fecha   520 non-null    object\n",
      " 2   cuento  520 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos desde el archivo CSV\n",
    "file_path = 'blog_casciari.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Mostramos las columnas disponibles en el dataset\n",
    "print(\"Columnas disponibles en el dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Mostramos las primeras filas del dataframe para tener una idea general del contenido\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Mostramos un resumen básico del dataset\n",
    "print(\"\\nInformación del dataset:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd867005",
   "metadata": {},
   "source": [
    "Para traer los datos, cargue el archivo blog_casciari.csv utilizando la librería pandas y revise el contenido del dataset, donde primero se muestran las columnas disponibles en el archivo para identificar los nombres correctos, luego vemos las primeras filas del dataframe para obtener una vista previa de los datos y proporcionamos un resumen general del dataset con el método .info().\n",
    "\n",
    "El dataset cargado contiene 520 entradas y 3 columnas: 'titulo', 'fecha', y 'cuento'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8457323",
   "metadata": {},
   "source": [
    "### 2. Homogenización de textos\n",
    "\n",
    "Para cumplir con el objetivo de generar recomendaciones en esta sección debe preparar los posts para poder ser utilizados en su sistema de recomendación. Para ello, \"limpie\" y \"tokenize\" cada uno de los cuentos, describiendo detalladamente los pasos que realizo y si transformó o eliminó ciertas palabras. Para asistirlo en la tarea he creado listas de *stopwords* que están disponibles en la carpeta `data`. En su procedimiento ilustre la limpieza con el cuento 'La venganza del metegol'. (En su limpieza recuerde que el objetivo es generar recomendaciones a partir de la similitud de las palabras o temas de los cuentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d541df24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ahora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alejandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alguien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>éstos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>českomoravský</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>české</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>šeredova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>šeredovà</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ahora\n",
       "0        alejandro\n",
       "1             alex\n",
       "2          alfonso\n",
       "3          alguien\n",
       "4             allí\n",
       "..             ...\n",
       "163          éstos\n",
       "164  českomoravský\n",
       "165          české\n",
       "166       šeredova\n",
       "167       šeredovà\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar la lista de stopwords\n",
    "file_path = 'stopwords_taller.csv'\n",
    "custom_stopwords  = pd.read_csv(file_path)\n",
    "custom_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00efc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseguramos que las stopwords estén en minúsculas para una limpieza efectiva\n",
    "custom_stopwords = [word.lower() for word in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c13248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar y tokenizar el texto\n",
    "def clean_and_tokenize(text):\n",
    "    # Convertimos todo el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminamos caracteres no deseados como signos de puntuación, números y caracteres especiales\n",
    "    text = re.sub(r'[^a-zñáéíóúü\\s]', '', text)\n",
    "    \n",
    "    # Tokenizamos el texto (convertirlo en una lista de palabras)\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Eliminamos stopwords (palabras irrelevantes)\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed72b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cuentos tokenizados:\n",
      "                       titulo  \\\n",
      "0            El rincón blanco   \n",
      "1  Mínimos avances en la cama   \n",
      "2                  Don Marcos   \n",
      "3              Los dos rulfos   \n",
      "4   La noticia no es el perro   \n",
      "\n",
      "                                              tokens  \n",
      "0  [de, pronto, yo, estaba, en, el, hogar, donde,...  \n",
      "1  [menos, la, cama, todo, ha, mejorado, en, este...  \n",
      "2  [dos, veces, y, no, una, mi, abuelo, materno, ...  \n",
      "3  [a, su, regreso, de, méxico, mi, amigo, comequ...  \n",
      "4  [de, repente, un, video, de, you, tube, recibe...  \n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función a todos los cuentos\n",
    "df['tokens'] = df['cuento'].apply(clean_and_tokenize)\n",
    "\n",
    "# Mostramos las primeras filas con la columna de tokens\n",
    "print(\"\\nCuentos tokenizados:\")\n",
    "print(df[['titulo', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f7ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens del cuento 'La venganza del metegol':\n",
      "['el', 'mes', 'pasado', 'me', 'invitaron', 'a', 'presentar', 'un', 'libro', 'en', 'buenos', 'aires', 'y', 'como', 'era', 'un', 'libro', 'sobre', 'fútbol', 'al']\n",
      "\n",
      "Longitud original del cuento: 1137 palabras\n",
      "Longitud tras la limpieza: 1128 palabras\n"
     ]
    }
   ],
   "source": [
    "# Extraemos el cuento de 'La venganza del metegol' para el ejemplo\n",
    "cuento_example = df[df['titulo'] == 'La venganza del metegol']['cuento'].values[0]\n",
    "\n",
    "# Aplicamos la función de limpieza y tokenización al cuento\n",
    "tokens_cuento = clean_and_tokenize(cuento_example)\n",
    "\n",
    "# Mostramos los primeros tokens resultantes\n",
    "print(\"Tokens del cuento 'La venganza del metegol':\")\n",
    "print(tokens_cuento[:20])  # Mostramos solo los primeros 20 tokens para ilustrar el resultado\n",
    "\n",
    "# Mostramos la longitud del cuento original y del texto tokenizado para comparación\n",
    "print(f\"\\nLongitud original del cuento: {len(cuento_example.split())} palabras\")\n",
    "print(f\"Longitud tras la limpieza: {len(tokens_cuento)} palabras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7406aa",
   "metadata": {},
   "source": [
    "Para este punto se carga el archivo con las stopwords sugeridas, donde nos aseguramos que todas las palabras estén en minúsculas para facilitar la comparación con los tokens, luego se crea la función de limpieza y tokenización donde se convierte el texto a minúsculas para uniformar el formato, se eliminan los caracteres especiales, signos de puntuación y números que no son útiles para el análisis semántico.\n",
    "\n",
    "Finalmente Tokenizamos el texto en palabras utilizando word_tokeniz y eliminamos todas las palabras que están en la lista de stopwords para reducir el ruido y enfocarnos en palabras significativas.\n",
    "\n",
    "\n",
    "Transformación o eliminación de palabras:\n",
    "Todas las palabras se transforman a minúsculas.\n",
    "Se eliminan los caracteres especiales y números.\n",
    "Se eliminan las palabras irrelevantes según la lista de stopwords.\n",
    "\n",
    "A modo de revision se toma el cuento 'La venganza del metegol' y se hace la limpieza y tokenización de su contenido donde se observa que se paso de 1137 palabras antes a 1128 ahora luego de este paso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e07593",
   "metadata": {},
   "source": [
    "### 3. Generando Recomendaciones\n",
    "\n",
    "En esta sección nos interesa generar recomendaciones de cuentos en el blog a un usuario que leyó 'La venganza del metegol'. Para ello vamos a utilizar distintas estrategias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428c6d4",
   "metadata": {},
   "source": [
    "#### 3.1. Recomendaciones basadas en contenidos\n",
    "\n",
    "##### 3.1.1. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando en la distancia de coseno donde el texto este vectorizado por `CountVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f85147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol':\n",
      "1. Cuento con bruja y tramontina (Similitud: 0.9132)\n",
      "2. Primer asalto (Similitud: 0.9111)\n",
      "3. Lado A: música ligera (Similitud: 0.9081)\n",
      "4. La desgracia venía en sobres papel madera (Similitud: 0.9070)\n",
      "5. Electrodomésticos (Similitud: 0.9041)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "cosine_similarities = cosine_similarity(X[index_cuento_ejemplo], X).flatten()\n",
    "\n",
    "# Ordenamos los cuentos por similitud, excluyendo el propio cuento de referencia\n",
    "similar_cuentos_indices = cosine_similarities.argsort()[::-1][1:6]  # Tomamos los 5 más similares\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol':\")\n",
    "for i, idx in enumerate(similar_cuentos_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Similitud: {cosine_similarities[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fab6c9",
   "metadata": {},
   "source": [
    "Para generar las recomendaciones basadas en contenidos, vectoricé los cuentos usando CountVectorizer, que convierte el texto en una matriz de frecuencias de palabras, luego calculé la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos para medir qué tan similares son en cuanto a las palabras que usan y finalmente, ordené las recomendaciones de mayor a menor similitud de coseno, seleccionando los 5 cuentos con mayor similitud, excluyendo el propio cuento de referencia, donde podemos ver que el cuento con mayor similitud es Cuento con bruja y tramontina (Similitud: 0.9132), seguido por Primer asalto (Similitud: 0.9111),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680d49f",
   "metadata": {},
   "source": [
    "##### 3.1.2. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para  el cuento 'La venganza del metegol' usando nuevamente la distancia de coseno, pero ahora vectorice el texto usando `TF-IDFVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados del punto anterior y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de6bd627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol' (usando TF-IDF):\n",
      "1. Cuento con bruja y tramontina (Similitud: 0.4968)\n",
      "2. Gaussian blur (Similitud: 0.4960)\n",
      "3. Dice el Chiri, dice el Gordo (Similitud: 0.4956)\n",
      "4. La desgracia venía en sobres papel madera (Similitud: 0.4794)\n",
      "5. Matar la crisis a volantazos (Similitud: 0.4677)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "cosine_similarities_tfidf = cosine_similarity(X_tfidf[index_cuento_ejemplo], X_tfidf).flatten()\n",
    "\n",
    "# Ordenamos los cuentos por similitud, excluyendo el propio cuento de referencia\n",
    "similar_cuentos_indices_tfidf = cosine_similarities_tfidf.argsort()[::-1][1:6]\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando TF-IDF):\")\n",
    "for i, idx in enumerate(similar_cuentos_indices_tfidf):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Similitud: {cosine_similarities_tfidf[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6d61b0",
   "metadata": {},
   "source": [
    "Para este caso de generar las recomendaciones con TF-IDFVectorizer, transformé los cuentos en vectores ponderados según la relevancia de las palabras, en lugar de simplemente contar su frecuencia, calculé la similitud de coseno entre el vector del cuento 'La venganza del metegol' y los vectores de los otros cuentos, y ordené los resultados de mayor a menor similitud, seleccionando los 5 cuentos más similares.\n",
    "\n",
    "Comparado con el método de CountVectorizer, que contaba palabras sin ponderar su relevancia, TF-IDF ofrece recomendaciones más ajustadas al dar más peso a palabras distintivas y menos a términos comunes, lo que hizo que aunque el cuento con mayor similitud siga siendo Cuento con bruja y tramontina (Similitud: 0.4968) y la desgracia venía en sobres papel madera (Similitud: 0.4794) tambien sea recomendado, el segundo,tercero y quinto puesto si cambiaron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecc26a",
   "metadata": {},
   "source": [
    "##### 3.1.3. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando el texto vectorizado por `TF-IDFVectorizer` y la correlación como medida de similitud. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados de los puntos anteriores y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0dfdda41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol' (usando Correlación):\n",
      "1. Cuento con bruja y tramontina (Correlación: 0.4927)\n",
      "2. Gaussian blur (Correlación: 0.4920)\n",
      "3. Dice el Chiri, dice el Gordo (Correlación: 0.4915)\n",
      "4. La desgracia venía en sobres papel madera (Correlación: 0.4752)\n",
      "5. Matar la crisis a volantazos (Correlación: 0.4633)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la correlación entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "correlation_scores = []\n",
    "for i in range(X_tfidf.shape[0]):\n",
    "    if i != index_cuento_ejemplo:\n",
    "        correlation_score = 1 - correlation(X_tfidf[index_cuento_ejemplo].toarray().flatten(), X_tfidf[i].toarray().flatten())\n",
    "        correlation_scores.append((i, correlation_score))\n",
    "\n",
    "# Ordenamos los cuentos por correlación\n",
    "sorted_correlation_scores = sorted(correlation_scores, key=lambda x: x[1], reverse=True)\n",
    "top_5_indices = [index for index, score in sorted_correlation_scores[:5]]\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando Correlación):\")\n",
    "for i, idx in enumerate(top_5_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Correlación: {sorted_correlation_scores[i][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a92cf",
   "metadata": {},
   "source": [
    "Para generar las recomendaciones usando correlación con TF-IDFVectorizer, convertí los cuentos en vectores ponderados y calculé la correlación entre el vector del cuento 'La venganza del metegol' y los vectores de los demás cuentos, luego ordené las recomendaciones según la correlación más alta, destacando los cuentos con patrones de términos similares y comparado con la similitud de coseno, la correlación también revela cuentos con significativos patrones de palabras, pero puede diferir en el ranking debido a su forma diferente de medir similitud. \n",
    "\n",
    "Los resultados muestran similitudes en la inclusión de cuentos con términos relevantes, pero las diferencias en el orden reflejan las variaciones en cómo cada métrica interpreta la relación entre textos, nuevamente el cuento \"Cuento con bruja y tramontina\" ocupa el primer lugar y los demás cuentos son similares a los obtenidos en el punto anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f46e27",
   "metadata": {},
   "source": [
    "##### 3.2. Recomendaciones basadas en temas\n",
    "\n",
    "Usando modelado de temas con LDA, encuentre los temas subyacentes en el blog. Explique como eligió el numero óptimo de temas. Utilizando el tema asignado al cuento 'La venganza del metegol' y la probabilidad de pertenecer a este tema genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para este cuento. Explique el procedimiento que realizó. Compare con los resultados encontrados anteriormente y explique sus similitudes y/o diferencias. (Esto puede tomar mucho tiempo y requerir mucha capacidad computacional, puede aprovechar los recursos de [Google Colab](https://colab.research.google.com/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "928e25c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol' (usando LDA):\n",
      "1. Ropa sucia (Probabilidad de pertenencia al tema: 0.9998)\n",
      "2. 10.6 segundos (Probabilidad de pertenencia al tema: 0.9998)\n",
      "3. Escupir el asado (Probabilidad de pertenencia al tema: 0.9998)\n",
      "4. Papelitos (Probabilidad de pertenencia al tema: 0.9998)\n",
      "5. Basdala (Probabilidad de pertenencia al tema: 0.9998)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    return text.lower().split()  # Tokenización básica por espacios\n",
    "\n",
    "# Aplicar el preprocesamiento\n",
    "texts = df['cuento'].map(preprocess_text)\n",
    "\n",
    "# Crear un diccionario y corpus para LDA\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Evaluar modelos LDA con diferentes números de temas\n",
    "num_topics_range = [5, 10, 15, 20]\n",
    "coherence_scores = []\n",
    "perplexities = []\n",
    "\n",
    "for num_topics in num_topics_range:\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Calcular la coherencia del modelo\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append((num_topics, coherence_score))\n",
    "\n",
    "    # Calcular la perplejidad del modelo\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    perplexities.append((num_topics, perplexity))\n",
    "\n",
    "# Elegir el mejor número de temas basado en la coherencia\n",
    "best_n_topics_coherence = max(coherence_scores, key=lambda x: x[1])[0]\n",
    "\n",
    "# Entrenar el modelo LDA con el número óptimo de temas\n",
    "lda_best = models.LdaModel(corpus, num_topics=best_n_topics_coherence, id2word=dictionary, passes=10)\n",
    "\n",
    "# Visualización del modelo LDA (opcional, si tienes pyLDAvis instalado)\n",
    "# pyLDAvis.save_html(pyLDAvis.gensim.prepare(lda_best, corpus, dictionary), 'lda_visualization.html')\n",
    "\n",
    "# Asignación de temas y cálculo de probabilidades\n",
    "# Obtener las probabilidades de pertenencia a cada tema para cada cuento\n",
    "topic_probabilities = np.array([[prob[1] for prob in lda_best.get_document_topics(doc, minimum_probability=0)] for doc in corpus])\n",
    "\n",
    "# Obtener el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Identificar el tema principal al que pertenece el cuento 'La venganza del metegol'\n",
    "tema_ejemplo = topic_probabilities[index_cuento_ejemplo].argmax()\n",
    "\n",
    "# Selección de los 5 cuentos más similares basados en la probabilidad de pertenencia al mismo tema\n",
    "similarity_scores = [(i, topic_probabilities[i][tema_ejemplo]) for i in range(len(df)) if i != index_cuento_ejemplo]\n",
    "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "top_5_indices = [index for index, score in sorted_similarity_scores[:5]]\n",
    "\n",
    "# Mostrar las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando LDA):\")\n",
    "for i, idx in enumerate(top_5_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Probabilidad de pertenencia al tema: {sorted_similarity_scores[i][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01d4674",
   "metadata": {},
   "source": [
    "En esta parte, utilicé el modelado de temas con LDA para analizar los cuentos y encontrar los temas subyacentes. Preprocesé los textos, creando un diccionario y un corpus para entrenar varios modelos LDA con diferentes números de temas. Elegí el mejor modelo basándome en la coherencia del mismo y luego, usando el tema asignado al cuento \"La venganza del metegol\", generé 5 recomendaciones de cuentos similares. Estas recomendaciones están ordenadas según su probabilidad de pertenencia al mismo tema, permitiéndome identificar las historias más relacionadas temáticamente.\n",
    "\n",
    "Utilizando el modelo LDA para recomendar cuentos similares a *'La venganza del metegol'*, obtuvimos resultados que muestran alta coherencia temática, con todos los cuentos recomendados teniendo una probabilidad de pertenencia al tema de 0.9998. Esto indica que estos cuentos son altamente relevantes para el tema del cuento de referencia, sugiriendo que el modelo ha capturado efectivamente el tema dominante. En comparación con métodos basados en `CountVectorizer` y `TF-IDF`, que se centran en la similitud textual directa, LDA ofrece recomendaciones basadas en temas subyacentes, lo que puede ser útil para explorar contenido relacionado en un contexto temático más amplio.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26364c1c",
   "metadata": {},
   "source": [
    "### 4 Recomendaciones generales\n",
    "\n",
    "De acuerdo con los resultados encontrados, en su opinión ¿qué procedimiento generó las mejores recomendaciones para la entrada elegida? ¿Cómo implementaría una evaluación objetiva de estas recomendaciones? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3aa3a",
   "metadata": {},
   "source": [
    "*Recomendaciones*\n",
    "\n",
    "De acuerdo con los resultados obtenidos, el procedimiento de Latent Dirichlet Allocation (LDA) generó las recomendaciones más coherentes para el cuento *'La venganza del metegol'*. Esto se debe a que LDA identificó un tema dominante al que todos los cuentos recomendados tienen una alta probabilidad de pertenencia, sugiriendo que estos cuentos están bien alineados temáticamente con el cuento de referencia, esto ya que LDA ofrece una perspectiva más abstracta al centrarse en temas subyacentes, proporcionando recomendaciones basadas en la coherencia temática general en lugar de coincidencias textuales específicas. Esto puede ser más útil para descubrir contenido relevante que comparte contextos similares, lo cual es valioso en sistemas de recomendación basados en temas.\n",
    "\n",
    "Los métodos basados en `CountVectorizer` y `TF-IDFVectorizer`, aunque son útiles para medir similitudes textuales exactas, pueden no capturar el contexto temático completo, resultando en recomendaciones que se centran más en la similitud de palabras que en el significado subyacente del contenido.\n",
    "\n",
    "Evaluación Objetiva:\n",
    "\n",
    "1.Utilizar métricas como la coherencia de temas para evaluar la calidad de los temas generados por LDA. La coherencia mide la consistencia y la interpretabilidad de los temas generados. Se pueden usar medidas como `coherence_score` para cuantificar cuán bien los términos en cada tema están relacionados entre sí.\n",
    "\n",
    "2.Evaluación Humana:Realizar una evaluación manual de las recomendaciones para comprobar si las recomendaciones generadas son realmente relevantes para el cuento de referencia en términos de contenido y tema. Esto puede implicar una revisión cualitativa de las recomendaciones para confirmar su relevancia y coherencia.\n",
    "\n",
    "3.Comparación de Métodos: Comparar los resultados obtenidos con LDA frente a `CountVectorizer` y `TF-IDFVectorizer` en términos de relevancia y utilidad. Esto puede implicar medir la precisión de las recomendaciones al evaluar la satisfacción del usuario o la relevancia temática de las recomendaciones.\n",
    "\n",
    "4. Retroalimentación del Usuario:Implementar un sistema de retroalimentación en el que los usuarios puedan calificar la relevancia de las recomendaciones. Esto proporciona datos reales sobre la efectividad del sistema de recomendación desde la perspectiva del usuario final.\n",
    "\n",
    "En resumen, **LDA** parece ser el mejor método para generar recomendaciones temáticamente coherentes y relevantes. Para una evaluación objetiva, se deben utilizar métricas de coherencia de temas, evaluaciones manuales, comparaciones entre métodos y retroalimentación de usuarios para asegurar la efectividad del sistema de recomendación."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
