{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso-taller:  Recomendando el Blog de  Hernán Casciari \n",
    "\n",
    "\n",
    "[Hernán Casciari](https://hernancasciari.com/#bio), es un escritor argentino, que escribe blog posts con cuentos e historias  relacionadas con el futbol, su vida, infancia, y relaciones familiares con toques de ficción. Este [blog](https://hernancasciari.com/blog/) es  tan interesantes que en 2005 fue premiado como “El mejor blog del mundo” por Deutsche Welle de Alemania. \n",
    "\n",
    "El objetivo de este caso-taller es construir un sistema de recomendación basado en los contenidos de los posts utilizando similitud de las palabras usadas o temas de los cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "1. Para desarrollar el *cuaderno* primero debe descargarlo.\n",
    "\n",
    "2. Para responder cada inciso deberá utilizar el espacio debidamente especificado.\n",
    "\n",
    "3. La actividad será calificada sólo si sube el *cuaderno* de jupyter notebook con extensión `.ipynb` en la actividad designada como \"Revisión por el compañero.\"\n",
    "\n",
    "4. El archivo entregado debe poder ser ejecutado localmente por los pares. Sea cuidadoso con la especificación de la ubicación de los archivos de soporte, guarde la carpeta de datos  en la misma ruta de acceso del cuaderno, por ejemplo: `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "En la carpeta `data` se encuentran el archivo `blog_casciari.csv` con el título, la fecha de publicación, y el contenido de los cuentos publicados en el blog  de sr. Casciari. Cargue estos datos en su *cuaderno* y reporte brevemente el contenido de la base.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81194374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles en el dataset:\n",
      "Index(['titulo', 'fecha', 'cuento'], dtype='object')\n",
      "\n",
      "Primeras 5 filas del dataset:\n",
      "                       titulo    fecha  \\\n",
      "0            El rincón blanco  1/11/08   \n",
      "1  Mínimos avances en la cama  1/24/08   \n",
      "2                  Don Marcos  2/19/08   \n",
      "3              Los dos rulfos  3/26/08   \n",
      "4   La noticia no es el perro  4/15/08   \n",
      "\n",
      "                                              cuento  \n",
      "0  De pronto yo estaba en el hogar donde pasé la ...  \n",
      "1  Menos la cama, todo ha mejorado en este mundo....  \n",
      "2  Dos veces, y no una, mi abuelo materno me ayud...  \n",
      "3  A su regreso de México, mi amigo Comequechu no...  \n",
      "4  De repente, un video de You Tube recibe un mil...  \n",
      "\n",
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   titulo  520 non-null    object\n",
      " 1   fecha   520 non-null    object\n",
      " 2   cuento  520 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los datos desde el archivo CSV\n",
    "file_path = 'blog_casciari.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Mostramos las columnas disponibles en el dataset\n",
    "print(\"Columnas disponibles en el dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Mostramos las primeras filas del dataframe para tener una idea general del contenido\n",
    "print(\"\\nPrimeras 5 filas del dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Mostramos un resumen básico del dataset\n",
    "print(\"\\nInformación del dataset:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para traer los datos, cargue el archivo blog_casciari.csv utilizando la librería pandas y revise el contenido del dataset, donde primero se muestran las columnas disponibles en el archivo para identificar los nombres correctos, luego vemos las primeras filas del dataframe para obtener una vista previa de los datos y proporcionamos un resumen general del dataset con el método .info().\n",
    "\n",
    "El dataset cargado contiene 520 entradas y 3 columnas: 'titulo', 'fecha', y 'cuento'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Homogenización de textos\n",
    "\n",
    "Para cumplir con el objetivo de generar recomendaciones en esta sección debe preparar los posts para poder ser utilizados en su sistema de recomendación. Para ello, \"limpie\" y \"tokenize\" cada uno de los cuentos, describiendo detalladamente los pasos que realizo y si transformó o eliminó ciertas palabras. Para asistirlo en la tarea he creado listas de *stopwords* que están disponibles en la carpeta `data`. En su procedimiento ilustre la limpieza con el cuento 'La venganza del metegol'. (En su limpieza recuerde que el objetivo es generar recomendaciones a partir de la similitud de las palabras o temas de los cuentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ahora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alejandro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alguien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>allí</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>éstos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>českomoravský</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>české</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>šeredova</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>šeredovà</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ahora\n",
       "0        alejandro\n",
       "1             alex\n",
       "2          alfonso\n",
       "3          alguien\n",
       "4             allí\n",
       "..             ...\n",
       "163          éstos\n",
       "164  českomoravský\n",
       "165          české\n",
       "166       šeredova\n",
       "167       šeredovà\n",
       "\n",
       "[168 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar la lista de stopwords\n",
    "file_path = 'stopwords_taller.csv'\n",
    "custom_stopwords  = pd.read_csv(file_path)\n",
    "custom_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00efc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseguramos que las stopwords estén en minúsculas para una limpieza efectiva\n",
    "custom_stopwords = [word.lower() for word in custom_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c13248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar y tokenizar el texto\n",
    "def clean_and_tokenize(text):\n",
    "    # Convertimos todo el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Eliminamos caracteres no deseados como signos de puntuación, números y caracteres especiales\n",
    "    text = re.sub(r'[^a-zñáéíóúü\\s]', '', text)\n",
    "    \n",
    "    # Tokenizamos el texto (convertirlo en una lista de palabras)\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Eliminamos stopwords (palabras irrelevantes)\n",
    "    tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed72b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cuentos tokenizados:\n",
      "                       titulo  \\\n",
      "0            El rincón blanco   \n",
      "1  Mínimos avances en la cama   \n",
      "2                  Don Marcos   \n",
      "3              Los dos rulfos   \n",
      "4   La noticia no es el perro   \n",
      "\n",
      "                                              tokens  \n",
      "0  [de, pronto, yo, estaba, en, el, hogar, donde,...  \n",
      "1  [menos, la, cama, todo, ha, mejorado, en, este...  \n",
      "2  [dos, veces, y, no, una, mi, abuelo, materno, ...  \n",
      "3  [a, su, regreso, de, méxico, mi, amigo, comequ...  \n",
      "4  [de, repente, un, video, de, you, tube, recibe...  \n"
     ]
    }
   ],
   "source": [
    "# Aplicamos la función a todos los cuentos\n",
    "df['tokens'] = df['cuento'].apply(clean_and_tokenize)\n",
    "\n",
    "# Mostramos las primeras filas con la columna de tokens\n",
    "print(\"\\nCuentos tokenizados:\")\n",
    "print(df[['titulo', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75f7ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens del cuento 'La venganza del metegol':\n",
      "['el', 'mes', 'pasado', 'me', 'invitaron', 'a', 'presentar', 'un', 'libro', 'en', 'buenos', 'aires', 'y', 'como', 'era', 'un', 'libro', 'sobre', 'fútbol', 'al']\n",
      "\n",
      "Longitud original del cuento: 1137 palabras\n",
      "Longitud tras la limpieza: 1128 palabras\n"
     ]
    }
   ],
   "source": [
    "# Extraemos el cuento de 'La venganza del metegol' para el ejemplo\n",
    "cuento_example = df[df['titulo'] == 'La venganza del metegol']['cuento'].values[0]\n",
    "\n",
    "# Aplicamos la función de limpieza y tokenización al cuento\n",
    "tokens_cuento = clean_and_tokenize(cuento_example)\n",
    "\n",
    "# Mostramos los primeros tokens resultantes\n",
    "print(\"Tokens del cuento 'La venganza del metegol':\")\n",
    "print(tokens_cuento[:20])  # Mostramos solo los primeros 20 tokens para ilustrar el resultado\n",
    "\n",
    "# Mostramos la longitud del cuento original y del texto tokenizado para comparación\n",
    "print(f\"\\nLongitud original del cuento: {len(cuento_example.split())} palabras\")\n",
    "print(f\"Longitud tras la limpieza: {len(tokens_cuento)} palabras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este punto se carga el archivo con las stopwords sugeridas, donde nos aseguramos que todas las palabras estén en minúsculas para facilitar la comparación con los tokens, luego se crea la función de limpieza y tokenización donde se convierte el texto a minúsculas para uniformar el formato, se eliminan los caracteres especiales, signos de puntuación y números que no son útiles para el análisis semántico.\n",
    "\n",
    "Finalmente Tokenizamos el texto en palabras utilizando word_tokeniz y eliminamos todas las palabras que están en la lista de stopwords para reducir el ruido y enfocarnos en palabras significativas.\n",
    "\n",
    "\n",
    "Transformación o eliminación de palabras:\n",
    "Todas las palabras se transforman a minúsculas.\n",
    "Se eliminan los caracteres especiales y números.\n",
    "Se eliminan las palabras irrelevantes según la lista de stopwords.\n",
    "\n",
    "A modo de revision se toma el cuento 'La venganza del metegol' y se hace la limpieza y tokenización de su contenido donde se observa que se paso de 1137 palabras antes a 1128 ahora luego de este paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generando Recomendaciones\n",
    "\n",
    "En esta sección nos interesa generar recomendaciones de cuentos en el blog a un usuario que leyó 'La venganza del metegol'. Para ello vamos a utilizar distintas estrategias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Recomendaciones basadas en contenidos\n",
    "\n",
    "##### 3.1.1. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando en la distancia de coseno donde el texto este vectorizado por `CountVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol':\n",
      "1. Cuento con bruja y tramontina (Similitud: 0.9132)\n",
      "2. Primer asalto (Similitud: 0.9111)\n",
      "3. Lado A: música ligera (Similitud: 0.9081)\n",
      "4. La desgracia venía en sobres papel madera (Similitud: 0.9070)\n",
      "5. Electrodomésticos (Similitud: 0.9041)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "cosine_similarities = cosine_similarity(X[index_cuento_ejemplo], X).flatten()\n",
    "\n",
    "# Ordenamos los cuentos por similitud, excluyendo el propio cuento de referencia\n",
    "similar_cuentos_indices = cosine_similarities.argsort()[::-1][1:6]  # Tomamos los 5 más similares\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol':\")\n",
    "for i, idx in enumerate(similar_cuentos_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Similitud: {cosine_similarities[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar las recomendaciones basadas en contenidos, vectoricé los cuentos usando CountVectorizer, que convierte el texto en una matriz de frecuencias de palabras, luego calculé la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos para medir qué tan similares son en cuanto a las palabras que usan y finalmente, ordené las recomendaciones de mayor a menor similitud de coseno, seleccionando los 5 cuentos con mayor similitud, excluyendo el propio cuento de referencia, donde podemos ver que el cuento con mayor similitud es Cuento con bruja y tramontina (Similitud: 0.9132), seguido por Primer asalto (Similitud: 0.9111),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para  el cuento 'La venganza del metegol' usando nuevamente la distancia de coseno, pero ahora vectorice el texto usando `TF-IDFVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados del punto anterior y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol' (usando TF-IDF):\n",
      "1. Cuento con bruja y tramontina (Similitud: 0.4968)\n",
      "2. Gaussian blur (Similitud: 0.4960)\n",
      "3. Dice el Chiri, dice el Gordo (Similitud: 0.4956)\n",
      "4. La desgracia venía en sobres papel madera (Similitud: 0.4794)\n",
      "5. Matar la crisis a volantazos (Similitud: 0.4677)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la similitud de coseno entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "cosine_similarities_tfidf = cosine_similarity(X_tfidf[index_cuento_ejemplo], X_tfidf).flatten()\n",
    "\n",
    "# Ordenamos los cuentos por similitud, excluyendo el propio cuento de referencia\n",
    "similar_cuentos_indices_tfidf = cosine_similarities_tfidf.argsort()[::-1][1:6]\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando TF-IDF):\")\n",
    "for i, idx in enumerate(similar_cuentos_indices_tfidf):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Similitud: {cosine_similarities_tfidf[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso de generar las recomendaciones con TF-IDFVectorizer, transformé los cuentos en vectores ponderados según la relevancia de las palabras, en lugar de simplemente contar su frecuencia, calculé la similitud de coseno entre el vector del cuento 'La venganza del metegol' y los vectores de los otros cuentos, y ordené los resultados de mayor a menor similitud, seleccionando los 5 cuentos más similares.\n",
    "\n",
    "Comparado con el método de CountVectorizer, que contaba palabras sin ponderar su relevancia, TF-IDF ofrece recomendaciones más ajustadas al dar más peso a palabras distintivas y menos a términos comunes, lo que hizo que aunque el cuento con mayor similitud siga siendo Cuento con bruja y tramontina (Similitud: 0.4968) y la desgracia venía en sobres papel madera (Similitud: 0.4794) tambien sea recomendado, el segundo,tercero y quinto puesto si cambiaron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.3. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando el texto vectorizado por `TF-IDFVectorizer` y la correlación como medida de similitud. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados de los puntos anteriores y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones para 'La venganza del metegol' (usando Correlación):\n",
      "1. Cuento con bruja y tramontina (Correlación: 0.4927)\n",
      "2. Gaussian blur (Correlación: 0.4920)\n",
      "3. Dice el Chiri, dice el Gordo (Correlación: 0.4915)\n",
      "4. La desgracia venía en sobres papel madera (Correlación: 0.4752)\n",
      "5. Matar la crisis a volantazos (Correlación: 0.4633)\n"
     ]
    }
   ],
   "source": [
    "# Vectorización de los textos utilizando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento'])\n",
    "\n",
    "# Obtenemos el índice del cuento 'La venganza del metegol'\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "# Calculamos la correlación entre el cuento 'La venganza del metegol' y los demás cuentos\n",
    "correlation_scores = []\n",
    "for i in range(X_tfidf.shape[0]):\n",
    "    if i != index_cuento_ejemplo:\n",
    "        correlation_score = 1 - correlation(X_tfidf[index_cuento_ejemplo].toarray().flatten(), X_tfidf[i].toarray().flatten())\n",
    "        correlation_scores.append((i, correlation_score))\n",
    "\n",
    "# Ordenamos los cuentos por correlación\n",
    "sorted_correlation_scores = sorted(correlation_scores, key=lambda x: x[1], reverse=True)\n",
    "top_5_indices = [index for index, score in sorted_correlation_scores[:5]]\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando Correlación):\")\n",
    "for i, idx in enumerate(top_5_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Correlación: {sorted_correlation_scores[i][1]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a92cf",
   "metadata": {},
   "source": [
    "Para generar las recomendaciones usando correlación con TF-IDFVectorizer, convertí los cuentos en vectores ponderados y calculé la correlación entre el vector del cuento 'La venganza del metegol' y los vectores de los demás cuentos, luego ordené las recomendaciones según la correlación más alta, destacando los cuentos con patrones de términos similares y comparado con la similitud de coseno, la correlación también revela cuentos con significativos patrones de palabras, pero puede diferir en el ranking debido a su forma diferente de medir similitud. \n",
    "\n",
    "Los resultados muestran similitudes en la inclusión de cuentos con términos relevantes, pero las diferencias en el orden reflejan las variaciones en cómo cada métrica interpreta la relación entre textos, nuevamente el cuento \"Cuento con bruja y tramontina\" ocupa el primer lugar y los demás cuentos son similares a los obtenidos en el punto anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2. Recomendaciones basadas en temas\n",
    "\n",
    "Usando modelado de temas con LDA, encuentre los temas subyacentes en el blog. Explique como eligió el numero óptimo de temas. Utilizando el tema asignado al cuento 'La venganza del metegol' y la probabilidad de pertenecer a este tema genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para este cuento. Explique el procedimiento que realizó. Compare con los resultados encontrados anteriormente y explique sus similitudes y/o diferencias. (Esto puede tomar mucho tiempo y requerir mucha capacidad computacional, puede aprovechar los recursos de [Google Colab](https://colab.research.google.com/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m best_n_topics_coherence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(coherence_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo LDA con el número óptimo de temas\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m lda_best \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_n_topics_coherence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Visualización del modelo LDA\u001b[39;00m\n\u001b[0;32m     37\u001b[0m vis \u001b[38;5;241m=\u001b[39m gensimvis\u001b[38;5;241m.\u001b[39mprepare(lda_best, corpus, dictionary)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    525\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\ldamodel.py:1006\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1004\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m   1005\u001b[0m     )\n\u001b[1;32m-> 1006\u001b[0m     gammat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_alpha:\n\u001b[0;32m   1009\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_alpha(gammat, rho())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\ldamodel.py:768\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    767\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m--> 768\u001b[0m gamma, sstats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_sstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    769\u001b[0m state\u001b[38;5;241m.\u001b[39msstats \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sstats\n\u001b[0;32m    770\u001b[0m state\u001b[38;5;241m.\u001b[39mnumdocs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gensim\\models\\ldamodel.py:722\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    720\u001b[0m Elogthetad \u001b[38;5;241m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m    721\u001b[0m expElogthetad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(Elogthetad)\n\u001b[1;32m--> 722\u001b[0m phinorm \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpElogthetad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpElogbetad\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m epsilon\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# If gamma hasn't changed much, we're done.\u001b[39;00m\n\u001b[0;32m    724\u001b[0m meanchange \u001b[38;5;241m=\u001b[39m mean_absolute_difference(gammad, lastgamma)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Implementar el preprocesamiento necesario (tokenización, eliminación de stopwords, etc.)\n",
    "    return text.lower().split()  # Ejemplo simple\n",
    "\n",
    "# Aplicar el preprocesamiento\n",
    "texts = df['cuento'].map(preprocess_text)\n",
    "\n",
    "# Crear un diccionario y corpus\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Evaluar modelos LDA con diferentes números de temas\n",
    "num_topics_range = [5, 10, 15, 20]\n",
    "coherence_scores = []\n",
    "perplexities = []\n",
    "\n",
    "for num_topics in num_topics_range:\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)\n",
    "    \n",
    "    # Coherencia del modelo\n",
    "    coherence_model = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append((num_topics, coherence_score))\n",
    "\n",
    "    # Perplejidad del modelo\n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    perplexities.append((num_topics, perplexity))\n",
    "\n",
    "# Elegir el mejor número de temas basado en coherencia\n",
    "best_n_topics_coherence = max(coherence_scores, key=lambda x: x[1])[0]\n",
    "\n",
    "# Entrenar el modelo LDA con el número óptimo de temas\n",
    "lda_best = models.LdaModel(corpus, num_topics=best_n_topics_coherence, id2word=dictionary, passes=10)\n",
    "\n",
    "# Visualización del modelo LDA\n",
    "vis = gensimvis.prepare(lda_best, corpus, dictionary)\n",
    "pyLDAvis.show(vis)\n",
    "\n",
    "# Asignación de temas y cálculo de probabilidades\n",
    "topic_probabilities = np.array([lda_best.get_document_topics(doc, minimum_probability=0) for doc in corpus])\n",
    "index_cuento_ejemplo = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "tema_ejemplo = topic_probabilities[index_cuento_ejemplo].argmax()\n",
    "\n",
    "# Selección de los 5 cuentos más similares\n",
    "similarity_scores = [(i, topic_probabilities[i, tema_ejemplo]) for i in range(len(df)) if i != index_cuento_ejemplo]\n",
    "sorted_similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "top_5_indices = [index for index, score in sorted_similarity_scores[:5]]\n",
    "\n",
    "# Mostramos las 5 recomendaciones\n",
    "print(\"Top 5 recomendaciones para 'La venganza del metegol' (usando LDA):\")\n",
    "for i, idx in enumerate(top_5_indices):\n",
    "    print(f\"{i+1}. {df['titulo'].iloc[idx]} (Probabilidad de pertenencia al tema: {sorted_similarity_scores[i][1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir el procedimiento, análisis, y conclusiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Recomendaciones generales\n",
    "\n",
    "De acuerdo con los resultados encontrados, en su opinión ¿qué procedimiento generó las mejores recomendaciones para la entrada elegida? ¿Cómo implementaría una evaluación objetiva de estas recomendaciones? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Utilice este espacio para describir su procedimiento)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
