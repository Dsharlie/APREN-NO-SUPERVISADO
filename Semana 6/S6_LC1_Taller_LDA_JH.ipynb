{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e523927b",
   "metadata": {},
   "source": [
    "<div >\n",
    "<img src = \"figs/ans_banner_1920x200.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dbeed0",
   "metadata": {},
   "source": [
    "# Caso-taller:  Recomendando el Blog de  Hernán Casciari \n",
    "\n",
    "\n",
    "[Hernán Casciari](https://hernancasciari.com/#bio), es un escritor argentino, que escribe blog posts con cuentos e historias  relacionadas con el futbol, su vida, infancia, y relaciones familiares con toques de ficción. Este [blog](https://hernancasciari.com/blog/) es  tan interesantes que en 2005 fue premiado como “El mejor blog del mundo” por Deutsche Welle de Alemania. \n",
    "\n",
    "El objetivo de este caso-taller es construir un sistema de recomendación basado en los contenidos de los posts utilizando similitud de las palabras usadas o temas de los cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c665df",
   "metadata": {},
   "source": [
    "## Instrucciones generales\n",
    "\n",
    "1. Para desarrollar el *cuaderno* primero debe descargarlo.\n",
    "\n",
    "2. Para responder cada inciso deberá utilizar el espacio debidamente especificado.\n",
    "\n",
    "3. La actividad será calificada sólo si sube el *cuaderno* de jupyter notebook con extensión `.ipynb` en la actividad designada como \"Revisión por el compañero.\"\n",
    "\n",
    "4. El archivo entregado debe poder ser ejecutado localmente por los pares. Sea cuidadoso con la especificación de la ubicación de los archivos de soporte, guarde la carpeta de datos  en la misma ruta de acceso del cuaderno, por ejemplo: `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4c561e",
   "metadata": {},
   "source": [
    "## Desarrollo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef9290",
   "metadata": {},
   "source": [
    "### 1. Carga de datos \n",
    "\n",
    "En la carpeta `data` se encuentran el archivo `blog_casciari.csv` con el título, la fecha de publicación, y el contenido de los cuentos publicados en el blog  de sr. Casciari. Cargue estos datos en su *cuaderno* y reporte brevemente el contenido de la base.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3cdd5657-f6ec-41ec-8a4c-42cbc1497bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libreria\n",
    "import pandas as pd\n",
    "import unidecode\n",
    "import re\n",
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7718bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 520 entries, 0 to 519\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   titulo  520 non-null    object\n",
      " 1   fecha   520 non-null    object\n",
      " 2   cuento  520 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 12.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cuento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El rincón blanco</td>\n",
       "      <td>1/11/08</td>\n",
       "      <td>De pronto yo estaba en el hogar donde pasé la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mínimos avances en la cama</td>\n",
       "      <td>1/24/08</td>\n",
       "      <td>Menos la cama, todo ha mejorado en este mundo....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don Marcos</td>\n",
       "      <td>2/19/08</td>\n",
       "      <td>Dos veces, y no una, mi abuelo materno me ayud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los dos rulfos</td>\n",
       "      <td>3/26/08</td>\n",
       "      <td>A su regreso de México, mi amigo Comequechu no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La noticia no es el perro</td>\n",
       "      <td>4/15/08</td>\n",
       "      <td>De repente, un video de You Tube recibe un mil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       titulo    fecha  \\\n",
       "0            El rincón blanco  1/11/08   \n",
       "1  Mínimos avances en la cama  1/24/08   \n",
       "2                  Don Marcos  2/19/08   \n",
       "3              Los dos rulfos  3/26/08   \n",
       "4   La noticia no es el perro  4/15/08   \n",
       "\n",
       "                                              cuento  \n",
       "0  De pronto yo estaba en el hogar donde pasé la ...  \n",
       "1  Menos la cama, todo ha mejorado en este mundo....  \n",
       "2  Dos veces, y no una, mi abuelo materno me ayud...  \n",
       "3  A su regreso de México, mi amigo Comequechu no...  \n",
       "4  De repente, un video de You Tube recibe un mil...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "file_path = 'blog_casciari.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df_info = df.info()\n",
    "print(df_info)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f81c8e",
   "metadata": {},
   "source": [
    "* Se realiza el cargue de la base, se puede cambiar el **file_path** para que coloque la direccion en donde reposa la base *datos_clientes.csv*\n",
    "* La base cuenta con Titulo, fecha de publicación y cuento. contiene 520 registros (ningún nulo), todas sus variables son de tipo \"object\" y todos sus cuentos son solo del 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fd90a",
   "metadata": {},
   "source": [
    "### 2. Homogenización de textos\n",
    "\n",
    "Para cumplir con el objetivo de generar recomendaciones en esta sección debe preparar los posts para poder ser utilizados en su sistema de recomendación. Para ello, \"limpie\" y \"tokenize\" cada uno de los cuentos, describiendo detalladamente los pasos que realizo y si transformó o eliminó ciertas palabras. Para asistirlo en la tarea he creado listas de *stopwords* que están disponibles en la carpeta `data`. En su procedimiento ilustre la limpieza con el cuento 'La venganza del metegol'. (En su limpieza recuerde que el objetivo es generar recomendaciones a partir de la similitud de las palabras o temas de los cuentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7e9fc99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilice este espacio para escribir el código.\n",
    "file_path_stopwords = 'extra_stopwords.csv'\n",
    "extra_stopwords = pd.read_csv(file_path_stopwords, sep=',',header=None)\n",
    "extra_stopwords.columns = ['stopwords']\n",
    "extra_stopwords=set(extra_stopwords['stopwords'].to_list())\n",
    "nlp.Defaults.stop_words |= extra_stopwords\n",
    "# out = unidecode.unidecode(df)\n",
    "# out = re.sub(\"[^\\\\w\\\\s]|\\n\", ' ', out)\n",
    "# out = re.sub(\"\\d+\", \"\", out)\n",
    "\n",
    "def text_cleaning(txt):\n",
    "    \n",
    "    # Eliminar caracteres especiales\n",
    "    out = unidecode.unidecode(txt)\n",
    "    out = re.sub(\"[^\\\\w\\\\s]|\\n\", ' ', out)\n",
    "    out = re.sub(\"\\d+\", \"\", out)\n",
    "    # Poner en minúsculas\n",
    "    out = out.lower()\n",
    "    # out = re.sub('tv', ' ', out)\n",
    "    # out = re.sub('miniserie', 'miniseriedetv', out)\n",
    "    out = re.sub('\\s+', ' ', out)\n",
    "    \n",
    "    #NLP object\n",
    "    out = nlp(out)\n",
    "    # Eliminar Stopwords\n",
    "    out = [token.text for token in out if not token.is_stop]\n",
    "    out = \" \".join(out)\n",
    "    # Obtener los lemas de cada palabra\n",
    "    lemmas =[token.lemma_ for token in nlp(out)]\n",
    "    # Convertir la lista de lemmas nuevamente a texto\n",
    "    out = \" \".join(lemmas)\n",
    "    # Remover palabras muy cortas\n",
    "    out = [token.text for token in nlp(out) if len(token) > 2]\n",
    "    out = \" \".join(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "12189b88-1a42-4103-a956-e133952cd244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cuento</th>\n",
       "      <th>cuento_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El rincón blanco</td>\n",
       "      <td>1/11/08</td>\n",
       "      <td>De pronto yo estaba en el hogar donde pasé la ...</td>\n",
       "      <td>hogar pasar infancia saber nariz ojo acostumbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mínimos avances en la cama</td>\n",
       "      <td>1/24/08</td>\n",
       "      <td>Menos la cama, todo ha mejorado en este mundo....</td>\n",
       "      <td>cama mejorado mundo cocinabar sopa fuego lenar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Don Marcos</td>\n",
       "      <td>2/19/08</td>\n",
       "      <td>Dos veces, y no una, mi abuelo materno me ayud...</td>\n",
       "      <td>abuelo materno ayudo escritor intencion conver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los dos rulfos</td>\n",
       "      <td>3/26/08</td>\n",
       "      <td>A su regreso de México, mi amigo Comequechu no...</td>\n",
       "      <td>regreso mexico amigo comequechu conto historia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La noticia no es el perro</td>\n",
       "      <td>4/15/08</td>\n",
       "      <td>De repente, un video de You Tube recibe un mil...</td>\n",
       "      <td>video you tube recibir millon visita autoro go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Instrucciones para la masturbación del hijo</td>\n",
       "      <td>8/18/07</td>\n",
       "      <td>Si lees estas líneas es porque hoy cumples tre...</td>\n",
       "      <td>lees linea cumpl trece ano muerto redacto bata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>El colmo de un campesino</td>\n",
       "      <td>9/24/07</td>\n",
       "      <td>Hace algunos días Natalia Méndez, una editora ...</td>\n",
       "      <td>natalia mendez editorar libro infantil soler l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>La decadencia del Hombre Corbata</td>\n",
       "      <td>10/16/07</td>\n",
       "      <td>El actual Hombre Corbata es el último eslabón ...</td>\n",
       "      <td>actual hombre corbato eslabon hombre disfrazad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>El sentido del olfato en los trenes</td>\n",
       "      <td>10/26/07</td>\n",
       "      <td>Mi nombre no importa; no voy a presentarme. Lo...</td>\n",
       "      <td>nombre importar presentarme importar cara apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>La madre de todas las desgracias</td>\n",
       "      <td>12/13/07</td>\n",
       "      <td>Los que vivimos tan lejos, con un Atlántico en...</td>\n",
       "      <td>vivir lejos atlantico tema tabu aterra saber s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          titulo     fecha  \\\n",
       "0                               El rincón blanco   1/11/08   \n",
       "1                     Mínimos avances en la cama   1/24/08   \n",
       "2                                     Don Marcos   2/19/08   \n",
       "3                                 Los dos rulfos   3/26/08   \n",
       "4                      La noticia no es el perro   4/15/08   \n",
       "..                                           ...       ...   \n",
       "515  Instrucciones para la masturbación del hijo   8/18/07   \n",
       "516                     El colmo de un campesino   9/24/07   \n",
       "517             La decadencia del Hombre Corbata  10/16/07   \n",
       "518          El sentido del olfato en los trenes  10/26/07   \n",
       "519             La madre de todas las desgracias  12/13/07   \n",
       "\n",
       "                                                cuento  \\\n",
       "0    De pronto yo estaba en el hogar donde pasé la ...   \n",
       "1    Menos la cama, todo ha mejorado en este mundo....   \n",
       "2    Dos veces, y no una, mi abuelo materno me ayud...   \n",
       "3    A su regreso de México, mi amigo Comequechu no...   \n",
       "4    De repente, un video de You Tube recibe un mil...   \n",
       "..                                                 ...   \n",
       "515  Si lees estas líneas es porque hoy cumples tre...   \n",
       "516  Hace algunos días Natalia Méndez, una editora ...   \n",
       "517  El actual Hombre Corbata es el último eslabón ...   \n",
       "518  Mi nombre no importa; no voy a presentarme. Lo...   \n",
       "519  Los que vivimos tan lejos, con un Atlántico en...   \n",
       "\n",
       "                                        cuento_cleaned  \n",
       "0    hogar pasar infancia saber nariz ojo acostumbr...  \n",
       "1    cama mejorado mundo cocinabar sopa fuego lenar...  \n",
       "2    abuelo materno ayudo escritor intencion conver...  \n",
       "3    regreso mexico amigo comequechu conto historia...  \n",
       "4    video you tube recibir millon visita autoro go...  \n",
       "..                                                 ...  \n",
       "515  lees linea cumpl trece ano muerto redacto bata...  \n",
       "516  natalia mendez editorar libro infantil soler l...  \n",
       "517  actual hombre corbato eslabon hombre disfrazad...  \n",
       "518  nombre importar presentarme importar cara apar...  \n",
       "519  vivir lejos atlantico tema tabu aterra saber s...  \n",
       "\n",
       "[520 rows x 4 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cuento_cleaned'] = df['cuento'].apply(text_cleaning)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4bf4c36b-e3b3-4304-b8c7-ad4558406c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titulo</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cuento</th>\n",
       "      <th>cuento_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>La venganza del metegol</td>\n",
       "      <td>11/17/15</td>\n",
       "      <td>El mes pasado me invitaron a presentar un libr...</td>\n",
       "      <td>mes invitar presentar libro aires libro futbol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      titulo     fecha  \\\n",
       "160  La venganza del metegol  11/17/15   \n",
       "\n",
       "                                                cuento  \\\n",
       "160  El mes pasado me invitaron a presentar un libr...   \n",
       "\n",
       "                                        cuento_cleaned  \n",
       "160  mes invitar presentar libro aires libro futbol...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuento_metegol = df[df['titulo'] == 'La venganza del metegol']\n",
    "cuento_metegol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becb53d",
   "metadata": {},
   "source": [
    "1. Llamamos la base con los stopwords adicionales y las agregamos a las que tenemos en nuestro modelo de spacy\n",
    "   \n",
    "2. Luego creamos una funcion que realiza las siguientes tareas:\n",
    "- Se eliminan los caracteres especiales y las secuencias de dígitos numéricos.\n",
    "- Convertimos todo el texto a minúsculas.\n",
    "- Eliminamos los espacios adicionales que pueden haber quedado tras la eliminación de caracteres especiales.\n",
    "- Convertimos el texto en un objeto de procesamiento de lenguaje natural utilizando un modelo de spaCy.\n",
    "- Se eliminan todas las stopwords, tanto las incluidas por defecto en el modelo de spaCy como las que añadimos manualmente.\n",
    "- Se obtienen los lemas de las palabras, es decir, sus formas básicas o raíces. Por ejemplo, la palabra \"jugando\" se convierte en \"jugar\".\n",
    "- Eliminamos las palabras muy cortas (de dos caracteres o menos), que suelen ser irrelevantes en el análisis de texto.\n",
    "\n",
    "Para probar la función hacemos un filtro para el cuento llamado *La venganza del metegol* e ilustramos con es el cuento original y luego como se muestra al correr la función descrita anteriormente. Al usar la función vemos que el resultado es una lista con la limpieza y la tokenización del cuento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127e3ab",
   "metadata": {},
   "source": [
    "### 3. Generando Recomendaciones\n",
    "\n",
    "En esta sección nos interesa generar recomendaciones de cuentos en el blog a un usuario que leyó 'La venganza del metegol'. Para ello vamos a utilizar distintas estrategias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466619c7",
   "metadata": {},
   "source": [
    "#### 3.1. Recomendaciones basadas en contenidos\n",
    "\n",
    "##### 3.1.1. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando en la distancia de coseno donde el texto este vectorizado por `CountVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e4627027-5f2a-4e48-be9b-79677d6190f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones:\n",
      "1. Cuento con bruja y tramontina\n",
      "2. Una línea de puntos en un libro de catecismo\n",
      "3. El milagro de los pueblos\n",
      "4. Dice el Chiri, dice el Gordo\n",
      "5. Hace seis años también era domingo\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['cuento_cleaned'])\n",
    "\n",
    "idx_metegol = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "cos_sim = cosine_similarity(X[idx_metegol], X)\n",
    "\n",
    "similarity_scores = list(enumerate(cos_sim[0]))\n",
    "similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_5_recommendations = [df['titulo'][i] for i, _ in similarity_scores[1:6]]\n",
    "print(\"Top 5 recomendaciones:\")\n",
    "for i, title in enumerate(top_5_recommendations, 1):\n",
    "    print(f\"{i}. {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b8b82",
   "metadata": {},
   "source": [
    "Para realizar la recomendación usamos *CountVectorizer* para convertir los cuentos en vectores de términos, depués se identifica la posición del cuento *La venganza del metegol* ya con esto se calcula la distancio del coseno entre este cuento y el resto, se ordena de mayor a menor por similitud y se toman solo las 5 primeras recomendaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb51a55",
   "metadata": {},
   "source": [
    "##### 3.1.2. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para  el cuento 'La venganza del metegol' usando nuevamente la distancia de coseno, pero ahora vectorice el texto usando `TF-IDFVectorizer`. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados del punto anterior y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "52e4cd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones usando TF-IDF:\n",
      "1. Una línea de puntos en un libro de catecismo\n",
      "2. Cuento con bruja y tramontina\n",
      "3. Dice el Chiri, dice el Gordo\n",
      "4. Abrir y cerrar un círculo\n",
      "5. La foto de Wasmosy\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento_cleaned'])\n",
    "\n",
    "idx_metegol = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "cos_sim_tfidf = cosine_similarity(X_tfidf[idx_metegol], X_tfidf)\n",
    "\n",
    "similarity_scores_tfidf = list(enumerate(cos_sim_tfidf[0]))\n",
    "similarity_scores_tfidf = sorted(similarity_scores_tfidf, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "top_5_recommendations_tfidf = [df['titulo'][i] for i, _ in similarity_scores_tfidf[1:6]]\n",
    "print(\"Top 5 recomendaciones usando TF-IDF:\")\n",
    "for i, title in enumerate(top_5_recommendations_tfidf, 1):\n",
    "    print(f\"{i}. {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c43c7",
   "metadata": {},
   "source": [
    "Hacemos la transformación de la variable con el texto limpio y tokenizado, en este caso usamos TfidfVectorizer. Identificamos el indice de *La venganza del metegol*, con esto calculamos la similitud del coseno y ordenamos de mayor a menor esta distancia. Ya con esto identificamos cuales son los 5 cuentos con mayor similitud a *La venganza del metegol*.\n",
    "\n",
    "Se observa que 3 de los cuentos se mantienen en el top 5. Si uno realiza la lectura de lo cuentos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cc3f63",
   "metadata": {},
   "source": [
    "##### 3.1.3. Genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para el cuento 'La venganza del metegol' usando el texto vectorizado por `TF-IDFVectorizer` y la correlación como medida de similitud. Explique el procedimiento que realizó y como ordenó las recomendaciones. Compare con los resultados de los puntos anteriores y explique sus similitudes y/o diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "82c2ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recomendaciones usando correlación:\n",
      "1. Una línea de puntos en un libro de catecismo\n",
      "2. Cuento con bruja y tramontina\n",
      "3. Dice el Chiri, dice el Gordo\n",
      "4. La foto de Wasmosy\n",
      "5. Los jefes y los empleados\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cuento_cleaned'])\n",
    "\n",
    "idx_metegol = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "\n",
    "X_tfidf_array = X_tfidf.toarray()\n",
    "\n",
    "# Calcular la matriz de correlación entre todos los cuentos\n",
    "correlation_matrix = np.corrcoef(X_tfidf_array)\n",
    "\n",
    "# Extraer la fila correspondiente a \"La venganza del metegol\"\n",
    "correlation_metegol = correlation_matrix[idx_metegol]\n",
    "\n",
    "# Ordenar los cuentos según la correlación (de mayor a menor)\n",
    "similarity_scores_correlation = list(enumerate(correlation_metegol))\n",
    "similarity_scores_correlation = sorted(similarity_scores_correlation, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Obtener los 5 cuentos más recomendados (excluyendo el propio cuento)\n",
    "top_5_recommendations_correlation = [df['titulo'][i] for i, _ in similarity_scores_correlation[1:6]]\n",
    "\n",
    "# Mostrar las recomendaciones\n",
    "print(\"Top 5 recomendaciones usando correlación:\")\n",
    "for i, title in enumerate(top_5_recommendations_correlation, 1):\n",
    "    print(f\"{i}. {title}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba08b98",
   "metadata": {},
   "source": [
    "El procedimiento en está ocasión es el mismo del anterior, lo único que cambia, es la metrica que se usa para identificar cuales son los textos más similares a *La venganza del metegol*, en este caso hacemos uso de la correlación. Los resultados evidencian que con respecto al punto anterior, hay 4 cuentos similares que inclusiven mantienen el mismo orden y respecto al *CountVectorizer*  se mantienen 3 de estos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3dba5",
   "metadata": {},
   "source": [
    "##### 3.2. Recomendaciones basadas en temas\n",
    "\n",
    "Usando modelado de temas con LDA, encuentre los temas subyacentes en el blog. Explique como eligió el numero óptimo de temas. Utilizando el tema asignado al cuento 'La venganza del metegol' y la probabilidad de pertenecer a este tema genere 5 recomendaciones de más recomendada (1) a menos recomendada (5) para este cuento. Explique el procedimiento que realizó. Compare con los resultados encontrados anteriormente y explique sus similitudes y/o diferencias. (Esto puede tomar mucho tiempo y requerir mucha capacidad computacional, puede aprovechar los recursos de [Google Colab](https://colab.research.google.com/))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "07bfb0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.006*\"ano\" + 0.005*\"cosa\" + 0.005*\"casa\" + 0.003*\"viejo\" + 0.003*\"pasar\" + 0.003*\"hernar\" + 0.003*\"casciari\" + 0.003*\"gente\" + 0.003*\"luca\" + 0.003*\"ojo\"\n",
      "Topic: 1 \n",
      "Words: 0.008*\"ano\" + 0.004*\"tiempo\" + 0.004*\"mundo\" + 0.004*\"casciari\" + 0.003*\"casa\" + 0.003*\"mirar\" + 0.003*\"pasar\" + 0.003*\"cosa\" + 0.003*\"vida\" + 0.003*\"argentino\"\n",
      "Topic: 2 \n",
      "Words: 0.005*\"ano\" + 0.003*\"casa\" + 0.003*\"mirar\" + 0.003*\"mundo\" + 0.003*\"padre\" + 0.003*\"cosa\" + 0.003*\"tiempo\" + 0.003*\"quedar\" + 0.003*\"dejar\" + 0.003*\"pasar\"\n",
      "Topic: 3 \n",
      "Words: 0.006*\"ano\" + 0.005*\"casa\" + 0.004*\"cosa\" + 0.004*\"pasar\" + 0.004*\"mundo\" + 0.003*\"hernar\" + 0.003*\"mirar\" + 0.003*\"casciari\" + 0.003*\"noche\" + 0.003*\"dejar\"\n",
      "Top 5 recomendaciones basadas en LDA:\n",
      "1. La noticia no es el perro\n",
      "2. El móvil de Hansel y Gretel\n",
      "3. La trampa de McCracken\n",
      "4. La revancha\n",
      "5. Una cena demasiado larga\n"
     ]
    }
   ],
   "source": [
    "df['cuento_cleaned_2'] = df['cuento_cleaned'].apply(lambda x: [token.text for token in nlp(x) if not token.is_stop])\n",
    "\n",
    "dictionary = corpora.Dictionary(df['cuento_cleaned_2'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['cuento_cleaned_2']]\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, random_state=42)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary, corpus, df['cuento_cleaned_2'], limit=10)\n",
    "optimal_topics = model_list[coherence_values.index(max(coherence_values))]\n",
    "\n",
    "for idx, topic in optimal_topics.print_topics(-1):\n",
    "    print(f\"Topic: {idx} \\nWords: {topic}\")\n",
    "\n",
    "lda_corpus = optimal_topics[corpus]\n",
    "\n",
    "df['dominant_topic'] = [max(prob, key=lambda x: x[1])[0] for prob in lda_corpus]\n",
    "df['topic_probability'] = [max(prob, key=lambda x: x[1])[1] for prob in lda_corpus]\n",
    "\n",
    "idx_metegol = df[df['titulo'] == 'La venganza del metegol'].index[0]\n",
    "metegol_topic = df.loc[idx_metegol, 'dominant_topic']\n",
    "\n",
    "same_topic_cuentos = df[df['dominant_topic'] == metegol_topic].sort_values(by='topic_probability', ascending=False)\n",
    "\n",
    "top_5_recommendations_lda = same_topic_cuentos['titulo'].iloc[1:6].values\n",
    "print(\"Top 5 recomendaciones basadas en LDA:\")\n",
    "for i, title in enumerate(top_5_recommendations_lda, 1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb29115",
   "metadata": {},
   "source": [
    "Para poder realizar el modelo LDA es necesario tener en un formato especial el insumo, lo primero que hacemos es poner en este formato la información que ya se limpio. Creamos el diccionario y la bolsa de palabras para el LDA, creamos una función para seleccionar el número optimo de temas y se ejecuta con el diccionario creado, la bolsa de palabras, la variable en el formato requerido y un limite de tomas de 10 entonces es función probará del 1 al 10 para tomar el número optimo de temas y con esto ejecutar el modelo. En este caso el numero de temas optimo fue 4, con esto obtenemos las probabilidades del tema para cada cuento, asignamos el tema dominante de cada cuento, obtenemos los cuentos que tienen el mismo tema dominante que *La venganza del metegol* y con esto generamos las 5 recomendaciones basadas en el tema.\n",
    "\n",
    "En este caso los resultados no sé parecen en nada comparadas con el resto de las metodologias usadas, este top 5 de cuentos nunca se habían observado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a34c6",
   "metadata": {},
   "source": [
    "### 4 Recomendaciones generales\n",
    "\n",
    "De acuerdo con los resultados encontrados, en su opinión ¿qué procedimiento generó las mejores recomendaciones para la entrada elegida? ¿Cómo implementaría una evaluación objetiva de estas recomendaciones? Justifique su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6295fe8",
   "metadata": {},
   "source": [
    "Muchos de los textos de Casciari son narraciones personales o anecdóticas que involucran situaciones cotidianas, se tocan temas de amistades y relaciones. Este caso puede haber un lenguaje muy similar en cada texto por lo que metodos basados en el uso de palabras pueden estar un tanto sesgados, por tal motivo, es mucho más valioso el analisis realizado por LDA pues este metodo clasifica los textos en grupos basados en temas latentes que pueden no ser obvios a partir de la similitud de palabras. Por eso mi recomendación sería usar el metodo LDA en esta caso, puede que en otros analisis los otros metodos arrojen mejores resultados y sean más eficientes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
